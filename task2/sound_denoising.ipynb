{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from glob import glob\n",
    "import librosa\n",
    "\n",
    "import soundfile\n",
    "\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model, Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GPU\n"
     ]
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "if len(tf.config.list_physical_devices('GPU'))==0:\n",
    "    print(\"Training CPU\")\n",
    "else:\n",
    "    print(\"Training GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mel(filepth=\"data/train.part1/noisy/25/25_88353_25-88353-0017.npy\"):\n",
    "    mel_spec=np.load(filepth).astype(np.float64)\n",
    "    return mel_spec\n",
    "\n",
    "\n",
    "def reconstruct_audio_from_mel(mel_spec, out='rec.flac'):\n",
    "    sr=16000\n",
    "    hop_length=2561 \n",
    "    fmin=20\n",
    "    fmax=8000\n",
    "\n",
    "    mel_spec = np.exp((mel_spec - 1)*10).T\n",
    "    y_inv = librosa.feature.inverse.mel_to_audio(M=mel_spec, sr=16000, n_fft=1024, hop_length=256, fmin=20, fmax=8000)\n",
    "    soundfile.write(out, y_inv, samplerate=sr)\n",
    "\n",
    "\n",
    "def show_mel_spectra(img_pth=\"data/train.part1/clean/31/31_121969_31-121969-0000.npy\"):\n",
    "    plt.figure(figsize=(20,6))\n",
    "    mel_img=np.load(img_pth)\n",
    "    mel_img = (mel_img-mel_img.mean()) / mel_img.std()\n",
    "    plt.imshow(mel_img.astype(np.float64).T)\n",
    "    print(mel_img.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = 80 # размер скользящего окна\n",
    "numSegments = 8 # кочличество фурье-веторов для авторегрессии "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load-ры исправить циклы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataGen(tf.keras.utils.Sequence):\n",
    "    numSegments = numSegments\n",
    "\n",
    "    def __init__(self, data_folders : list,\n",
    "                 batch_size,\n",
    "                 numSegments=numSegments,\n",
    "                 shuffle=True):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.numSegments = numSegments\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.file_paths = []\n",
    "        for data_folder in data_folders:\n",
    "            self.file_paths += list(zip(glob(f\"{data_folder}/noisy/*/*.npy\"), glob(f\"{data_folder}/clean/*/*.npy\")))\n",
    "            random.shuffle(self.file_paths)\n",
    "\n",
    "        self.n = len(self.file_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.file_paths)\n",
    "\n",
    "    @classmethod\n",
    "    def __load_noisy(cls, path):\n",
    "        mel_image = np.load(path)\n",
    "        mel_image_segmented = []\n",
    "        for i in range(cls.numSegments, len(mel_image) // cls.numSegments):\n",
    "            segment = np.expand_dims(mel_image[i:i+cls.numSegments].T, axis=-1)\n",
    "            mel_image_segmented.append(segment)\n",
    "        return tf.convert_to_tensor(mel_image_segmented)\n",
    "    \n",
    "    @classmethod\n",
    "    def __load_clean(cls, path):        \n",
    "        mel_image = np.load(path)\n",
    "        mel_image_segmented = []\n",
    "        for i in range(cls.numSegments, len(mel_image) // cls.numSegments):\n",
    "            segment = mel_image[i].T\n",
    "            segment = np.expand_dims(segment, axis=-1)\n",
    "            segment = np.expand_dims(segment, axis=-1)\n",
    "            mel_image_segmented.append(segment)\n",
    "        return tf.convert_to_tensor(mel_image_segmented)\n",
    "\n",
    "    def __get_data(self, file_path_batches):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        for pth in file_path_batches:\n",
    "            X_batch.extend(self.__load_noisy(pth[0]))\n",
    "            y_batch.extend(self.__load_clean(pth[1]))\n",
    "\n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path_batches = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(file_path_batches)        \n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = DenoisingDataGen(data_folders=[\"data/train.part1\"], batch_size=3)\n",
    "valgen = DenoisingDataGen(data_folders=[\"data/val\"], batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(l2_strength):\n",
    "  inputs = Input(shape=[numFeatures, numSegments, 1])\n",
    "  x = inputs\n",
    "\n",
    "  # 1 -----\n",
    "  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
    "  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip0)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # 2 -----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(skip1)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # 3 ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  \n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # 4 ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip1\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # 5 ----\n",
    "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = x + skip0\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = BatchNormalization()(x)\n",
    "\n",
    "  # 6 ----\n",
    "  x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
    "  x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(3e-4)\n",
    "  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss='mse', \n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(l2_strength=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4000/4000 [==============================] - 2163s 539ms/step - loss: 0.0911 - rmse: 0.3019 - val_loss: 0.0598 - val_rmse: 0.2445\n",
      "Epoch 2/3\n",
      "4000/4000 [==============================] - 1846s 461ms/step - loss: 0.0652 - rmse: 0.2554 - val_loss: 0.0694 - val_rmse: 0.2635\n",
      "Epoch 3/3\n",
      "4000/4000 [==============================] - 30227s 8s/step - loss: 0.0598 - rmse: 0.2446 - val_loss: 0.0459 - val_rmse: 0.2142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1539466c250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(traingen,\n",
    "          validation_data=valgen,\n",
    "          epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x154a060e070>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('my_checkpoint')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_noisy(mel_image, numSegments=8):\n",
    "    mel_image_segmented = []\n",
    "    for i in range(0, len(mel_image)-numSegments):\n",
    "        segment = np.expand_dims(mel_image[i:i+numSegments].T, axis=-1)\n",
    "        mel_image_segmented.append(segment)\n",
    "    return tf.convert_to_tensor(mel_image_segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpth_noisy = \"data/train.part1/noisy/25/25_88353_25-88353-0017.npy\"\n",
    "mel_noisy = load_mel(filepth=fpth_noisy)\n",
    "reconstruct_audio_from_mel(mel_noisy, \"mel_noisy.flac\")\n",
    "\n",
    "fpth_clean = fpth_noisy.replace(\"noisy\", \"clean\")\n",
    "mel_clean = load_mel(filepth=fpth_clean)\n",
    "reconstruct_audio_from_mel(mel_clean, \"mel_clean.flac\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mel_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_noisy = preprocess_noisy(mel_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([895, 80, 8, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_noisy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "mel_filtered = np.squeeze(model.predict(preprocessed_noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruct_audio_from_mel(mel_filtered, \"mel_filtered.flac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37be8c2ada5fcf1db1eeb82a2f5ebdcef3c64c503697d019115edff76835e14f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
