{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from glob import glob\n",
    "import librosa\n",
    "\n",
    "import soundfile\n",
    "\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
    "from tensorflow.keras import Model, Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GPU\n"
     ]
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()\n",
    "if len(tf.config.list_physical_devices('GPU'))==0:\n",
    "    print(\"Training CPU\")\n",
    "else:\n",
    "    print(\"Training GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mel(filepth=\"data/train.part1/noisy/25/25_88353_25-88353-0017.npy\"):\n",
    "    mel_spec=np.load(filepth).astype(np.float64)\n",
    "    return mel_spec\n",
    "\n",
    "\n",
    "def reconstruct_audio_from_mel(mel_spec, out='rec.flac'):\n",
    "    sr=16000\n",
    "    hop_length=2561 \n",
    "    fmin=20\n",
    "    fmax=8000\n",
    "\n",
    "    mel_spec = np.exp((mel_spec - 1)*10).T\n",
    "    y_inv = librosa.feature.inverse.mel_to_audio(M=mel_spec, sr=16000, n_fft=1024, hop_length=256, fmin=20, fmax=8000)\n",
    "    soundfile.write(out, y_inv, samplerate=sr)\n",
    "\n",
    "\n",
    "def show_mel_spectra(img_pth=\"data/train.part1/clean/31/31_121969_31-121969-0000.npy\"):\n",
    "    plt.figure(figsize=(20,6))\n",
    "    mel_img=np.load(img_pth)\n",
    "    mel_img = (mel_img-mel_img.mean()) / mel_img.std()\n",
    "    plt.imshow(mel_img.astype(np.float64).T)\n",
    "    print(mel_img.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = 80 # размер скользящего окна\n",
    "numSegments = 8 # кочличество фурье-веторов для авторегрессии "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingDataGen(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, data_folders : list,\n",
    "                 batch_size,\n",
    "                 numSegments=numSegments,\n",
    "                 shuffle=True):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.numSegments = numSegments\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.file_paths = []\n",
    "        for data_folder in data_folders:\n",
    "            self.file_paths += list(zip(glob(f\"{data_folder}/noisy/*/*.npy\"), glob(f\"{data_folder}/clean/*/*.npy\")))\n",
    "            random.shuffle(self.file_paths)\n",
    "\n",
    "        self.n = len(self.file_paths)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.file_paths)\n",
    "\n",
    "    def __load_noisy(self, path):\n",
    "        mel_image = np.load(path)[0:numSegments]\n",
    "        mel_image = mel_image.T\n",
    "        mel_image = np.expand_dims(mel_image, axis=-1)\n",
    "        return tf.convert_to_tensor(mel_image)\n",
    "\n",
    "    def __load_clear(self, path):\n",
    "        mel_image = np.load(path)[numSegments]\n",
    "        mel_image = mel_image.T\n",
    "        mel_image = np.expand_dims(mel_image, axis=-1)\n",
    "        mel_image = np.expand_dims(mel_image, axis=-1)\n",
    "        return tf.convert_to_tensor(mel_image)\n",
    "\n",
    "    def __get_data(self, file_path_batches):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "\n",
    "        X_batch.extend([self.__load_noisy(pth[0]) for pth in file_path_batches])\n",
    "        y_batch.extend([self.__load_clear(pth[1]) for pth in file_path_batches])\n",
    "\n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "\n",
    "        # print(X_batch[0].shape, y_batch[0].shape)\n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_path_batches = self.file_paths[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(file_path_batches)        \n",
    "        return X, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = DenoisingDataGen(data_folders=[\"data/train.part1\"], batch_size=3)\n",
    "valgen = DenoisingDataGen(data_folders=[\"data/val\"], batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 80, 1, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traingen[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(l2_strength):\n",
    "  inputs = Input(shape=[numFeatures, numSegments, 1])\n",
    "  x = inputs\n",
    "\n",
    "  # 1 -----\n",
    "  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
    "  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n",
    "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #                kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(skip0)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # # 2 -----\n",
    "  # x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #                kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(skip1)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # # 3 ----\n",
    "  # x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "  \n",
    "  # x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # # 4 ----\n",
    "  # x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #            kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = x + skip1\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # # 5 ----\n",
    "  # x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #            kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = x + skip0\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
    "  #             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
    "  # x = Activation('relu')(x)\n",
    "  # x = BatchNormalization()(x)\n",
    "\n",
    "  # # 6 ----\n",
    "  # x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
    "  # x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n",
    "\n",
    "  model = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(3e-4)\n",
    "  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n",
    "\n",
    "  model.compile(optimizer=optimizer, loss='mse', \n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(l2_strength=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_3/conv2d_32/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ankha\\AppData\\Local\\Temp\\ipykernel_4364\\326874305.py\", line 1, in <cell line: 1>\n      model.fit(traingen,\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_3/conv2d_32/Conv2D'\nDNN library is not found.\n\t [[{{node model_3/conv2d_32/Conv2D}}]] [Op:__inference_train_function_12191]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ankha\\Desktop\\repos\\Goznak-Intro\\task2\\sound_denoising.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ankha/Desktop/repos/Goznak-Intro/task2/sound_denoising.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(traingen,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ankha/Desktop/repos/Goznak-Intro/task2/sound_denoising.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49mvalgen,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ankha/Desktop/repos/Goznak-Intro/task2/sound_denoising.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ankha/Desktop/repos/Goznak-Intro/task2/sound_denoising.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnimplementedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_3/conv2d_32/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n      app.start()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ankha\\AppData\\Local\\Temp\\ipykernel_4364\\326874305.py\", line 1, in <cell line: 1>\n      model.fit(traingen,\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 250, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\ankha\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 225, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_3/conv2d_32/Conv2D'\nDNN library is not found.\n\t [[{{node model_3/conv2d_32/Conv2D}}]] [Op:__inference_train_function_12191]"
     ]
    }
   ],
   "source": [
    "model.fit(traingen,\n",
    "          validation_data=valgen,\n",
    "          epochs=3\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 81, 8, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadding2  (None, 89, 8, 1)    0           ['input_2[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 81, 1, 18)    1296        ['zero_padding2d_1[0][0]']       \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 81, 1, 18)    0           ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 81, 1, 18)   72          ['activation_15[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 81, 1, 30)    2700        ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 81, 1, 30)    0           ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 81, 1, 30)   120         ['activation_16[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 81, 1, 8)     2160        ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 81, 1, 8)     0           ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 81, 1, 8)    32          ['activation_17[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 81, 1, 18)    1296        ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 81, 1, 18)    0           ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 81, 1, 18)   72          ['activation_18[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 81, 1, 30)    2700        ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 81, 1, 30)    0           ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 81, 1, 30)   120         ['activation_19[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 81, 1, 8)     2160        ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 81, 1, 8)     0           ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 81, 1, 8)    32          ['activation_20[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 81, 1, 18)    1296        ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 81, 1, 18)    0           ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 81, 1, 18)   72          ['activation_21[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 81, 1, 30)    2700        ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 81, 1, 30)    0           ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 81, 1, 30)   120         ['activation_22[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 81, 1, 8)     2160        ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 81, 1, 8)     0           ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 81, 1, 8)    32          ['activation_23[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 81, 1, 18)    1296        ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 81, 1, 18)    0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 81, 1, 18)   72          ['activation_24[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 81, 1, 30)    2700        ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 81, 1, 30)   0           ['conv2d_26[0][0]',              \n",
      " mbda)                                                            'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 81, 1, 30)    0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 81, 1, 30)   120         ['activation_25[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 81, 1, 8)     2160        ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 81, 1, 8)     0           ['conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 81, 1, 8)    32          ['activation_26[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 81, 1, 18)    1296        ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 81, 1, 18)    0           ['conv2d_28[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 81, 1, 18)   72          ['activation_27[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 81, 1, 30)    2700        ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 81, 1, 30)   0           ['conv2d_29[0][0]',              \n",
      " mbda)                                                            'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 81, 1, 30)    0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 81, 1, 30)   120         ['activation_28[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 81, 1, 8)     2160        ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 81, 1, 8)     0           ['conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 81, 1, 8)    32          ['activation_29[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " spatial_dropout2d_1 (SpatialDr  (None, 81, 1, 8)    0           ['batch_normalization_29[0][0]'] \n",
      " opout2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 81, 1, 1)     1033        ['spatial_dropout2d_1[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 32,933\n",
      "Trainable params: 32,373\n",
      "Non-trainable params: 560\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37be8c2ada5fcf1db1eeb82a2f5ebdcef3c64c503697d019115edff76835e14f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
